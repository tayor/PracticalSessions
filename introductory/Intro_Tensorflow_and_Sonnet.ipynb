{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_Tensorflow_and_Sonnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nassma2019/PracticalSessions/blob/master/introductory/Intro_Tensorflow_and_Sonnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mh6dGF4NpnxX"
      },
      "source": [
        "# Introduction to Tensorflow and Sonnet\n",
        "\n",
        "By the end of this colab you will have trained a neural net to approximate the NXOR function based on some data. In the process you will have learnt about\n",
        "\n",
        "* some useful tensorflow tensor operations\n",
        "* building a model with *Tensorflow* and *Sonnet*\n",
        "* visualizing the model you built\n",
        "* getting the data into your model\n",
        "* backpropagation as implemented by tensorflow\n",
        "* debugging tensorflow models\n",
        "* how to actually train the network.\n",
        "\n",
        "Recall: you can use the outline on the right hand side to navigate the colab easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fTqcFF-_gDRD",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "#@title Fetching (DM) sonnet from pip. Run this cell.\n",
        "!pip install dm-sonnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HFzztlr1p1F9",
        "colab": {}
      },
      "source": [
        "#@title Imports. Run this cell.\n",
        "\n",
        "import random\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sonnet as snt\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import multivariate_normal\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "sns.set_style('ticks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "naSbSB6q1K1e",
        "colab": {}
      },
      "source": [
        "#@title Utility functions. Run this cell.\n",
        "\n",
        "def get_data(num_examples):\n",
        "  inputs = 2*np.random.random((num_examples, 2)) - 1\n",
        "  labels = np.prod(inputs, axis=1)\n",
        "  labels[labels <= 0] = -1 \n",
        "  labels[labels > 0] = 1 \n",
        "  return inputs, labels\n",
        "\n",
        "\n",
        "def plot_nxor_data(inputs, labels, title):\n",
        "  MARKER_COLORS = np.array([\n",
        "      [1.0, 0.0, 0.0],  # red for -1 \n",
        "      [0.0, 1.0, 0.0],  # green for +1\n",
        "  ])\n",
        "  class_idx = (labels + 1 / 2.0).astype(np.int)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.title(title)\n",
        "  plt.scatter(\n",
        "      x=inputs[:, 0], y=inputs[:, 1], c=MARKER_COLORS[class_idx], alpha=0.9)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = (\"<stripped %d bytes>\"%size).encode('utf8')\n",
        "    return strip_def\n",
        "\n",
        "  \n",
        "def show_graph(graph_def=None, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph. Default to the default graph.\"\"\"\n",
        "    if graph_def is None:\n",
        "      graph_def = tf.get_default_graph()\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVPFcNlJftrQ"
      },
      "source": [
        "## The TensorFlow Paradigm\n",
        "\n",
        "This section is not necessarily a fully complete introduction to tensorflow. If you are not familiar with tensorflow or don't feel comfortable with some of the content consider using a third party tutorial or the tensorflow documentation.\n",
        "\n",
        "Instead this colab focuses on exploring the ideas underlying tensorflow and working with it, highlighting important concepts along the way.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aPaS-ObaIuyE"
      },
      "source": [
        "**There are two distinct phases when it comes to working with tensorflow:**\n",
        "\n",
        "1. Constructing the computation graph, our model,\n",
        "2. Running data through this graph.\n",
        "\n",
        "We soon see what this means.\n",
        "\n",
        "*Note:* that with TensorFlow *Eager mode* this is not the case anymore: there the two phases happen hand in hand. Here we work with *Graph mode*, however."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OYynIRfG150V"
      },
      "source": [
        "### Building and displaying graphs\n",
        "\n",
        "Let's build a simple computation graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gpcEcp-8sKwE",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "a = tf.constant([5, 3, 1])\n",
        "b = tf.constant([-1, 2, 5])\n",
        "c = a + b\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Z7kU1QAsYRz"
      },
      "source": [
        "Notice that `c` has no value associated. It is actually a (reference to a) node in the computation graph we just defined: tensorflow knows that to find the value of `c`, it needs to query the values of the nodes `a` and `b` and add them. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pIhpA_m-vcjw"
      },
      "source": [
        "**In tensorflow all computation is implemented as operations on tensors (or variables, etc), and this computation forms a graph.**\n",
        "\n",
        "* We add tensors and operations to a graph with our Python code and libraries. \n",
        "* The tensorflow API [docs](https://www.tensorflow.org/api_docs/python/) list all available operations.\n",
        "* In practice many -- if not most -- `numpy` operations have a tensorflow counterpart, though often not by that same name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYB9fb3KzbdN"
      },
      "source": [
        "We can visualize the graph we have built so far. `show_graph()` is a utility function we defined above<sup>1</sup>; it shows the tensorboard graph representation of the graph you pass to it, right here in colab.\n",
        "\n",
        "<small>1: The graph visualization code is from the [Jakub Arnold Blog](https://blog.jakuba.net/2017/05/30/tensorflow-visualization.html#Using-a-cloud-hosted-TensorBoard-instance-to-do-the-rendering).</small>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i7mfP36k1dbz",
        "colab": {}
      },
      "source": [
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RC17oYAE1dhx"
      },
      "source": [
        "Note that in tensorflow you can have many graphs at the same time. By default, unless otherwise specified, we are building the so called \"default graph\" that we accessed with `tf.get_default_graph()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kXEufNds1uM-"
      },
      "source": [
        "### Resetting the default graph\n",
        "\n",
        "Recall that colab cells run in arbitrary order, maintaining python state between them. Therefore, if you run a cell that adds some tensors or operations to the graph, you will add more and more copies of them to the graph. This is probably not what you want.\n",
        "\n",
        "**Try running the cell where we defined node `c` a few more times, then visualizing the graph.** You will see multiply copies the same nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yfv-3PiDL4Tz"
      },
      "source": [
        "To solve this issue, tensorflow has `tf.reset_default_graph()`, which clears everything from the default graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yn7tl-2I2eqz",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "a = tf.constant(5, name='a')\n",
        "b = tf.constant(-1, name='b')\n",
        "c = tf.add(a, b, name='c')\n",
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Sg1A_YK1uSX"
      },
      "source": [
        "Whenever in doubt about your current graph, you can just reset it and rebuild it.\n",
        "\n",
        "By the way, notice that in the previous code cell we labelled nodes in the graph using the `name` argument. This can often help us interpret the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i6GT1cHLp1Lk"
      },
      "source": [
        "### Running the graph\n",
        "\n",
        "Recall that `c` had no associated value -- we were merely informed that it is a tensor, it's shape, etc. **Tensors only have values when 'run' in a session**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x9CnLzuW4DQW",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "a = tf.constant([5, 2], name='a')\n",
        "b = tf.constant([-1, 0], name='b')\n",
        "c = tf.add(a, b, name='c')\n",
        "\n",
        "with tf.Session() as session:\n",
        "  print(session.run(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N-DIUd_B0HBg"
      },
      "source": [
        "What really happens is that when you pass a graph node (operation, tensor, etc) to `session.run()`, tensorflow figures out what is the minimal subset of the graph to run in order to satisfy your request, and runs only that. It's difficult to appreciate this in the context of the simple graphs we had so far, but we will see a good example shortly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KLSwi1NBxj11"
      },
      "source": [
        "You can run any node from your graph, or a combination of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1gibFQ3_xkz1",
        "colab": {}
      },
      "source": [
        "with tf.Session() as session:\n",
        "  print('a:', session.run(a))  # As noted above, in this case addition\n",
        "                               # (required to find the value of c) is not even\n",
        "                               # executed.\n",
        "  print('[b, c]:', session.run([b, c]))\n",
        "  print(session.run({'a': a, 'c': c}))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UY1I6AnRzxKM"
      },
      "source": [
        "The data flows through the graph just once, but tensorflow runs all requested operations and tensors (along with their dependencies), returning their calculated values. We can easily illustrate how this work with tensors that get a new random value each time you run them. **Try predicting the pattern before inspecting the printed results!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0x5QAcq1rc4",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "r = tf.random_normal(shape=(3,), mean=0.0, stddev=1.0)\n",
        "x1 = r + 1  # Shifted +1\n",
        "x2 = r - 1  # Shifted -1\n",
        "\n",
        "with tf.Session() as session:\n",
        "  print('x1, x2 run separately:', session.run(x1), session.run(x2))\n",
        "  print('x1, x2 run together  :', session.run([x1, x2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HEP8J_ON3IhI"
      },
      "source": [
        "Notice that\n",
        "\n",
        "* when x1 and x2 were run together, the difference between correpsonding entries is always 2,\n",
        "* while this is not the case when they were run separately.\n",
        "\n",
        "This is because when run together, `r` is sampled once, and both `x1` and `x2` use this same value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U_6zhb8OPQ68"
      },
      "source": [
        "We now highlight what this means for neural network training implemented in tensorflow.\n",
        "\n",
        "### A neural network example of tensorflow's computational model \n",
        "\n",
        "All computation required to train the network will be implemented as a tensorflow computation graph. In particular you will have tensor and operations like\n",
        "\n",
        "* `train`: take a training step on some data,\n",
        "* `loss`: calculate the loss on some data,\n",
        "* `outputs`: give you predictions on some data,\n",
        "* and so on.\n",
        "\n",
        "Given the computation model of tensorflow:\n",
        "\n",
        "* You will be able to `run(loss)` to calculate the loss, and **without triggering the training step computation**.\n",
        "* On the other hand, running `train` will calculate the `loss` since this is what it needs to optimize.\n",
        "\n",
        "If you `run([loss, train])`, tensorflow will take a training step and report the loss, **both based on the same data**.\n",
        "\n",
        "\n",
        "As a final note, the fact that only the **minimal required subset of nodes are run** is going to be crucial when using BatchNorm: the ops that update the statistics kept in BatchNorm are not dependencies of any other ops, therefore will not get run automatically. You will experiment with this in the ConvNets and Vision Lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSLzoomC4yY3"
      },
      "source": [
        "### Running a graph with state and inputs\n",
        "\n",
        "Our examples so far have been silly in the sense that they were straightforward computation on constants, not warranting a computation graph. We now showcase a situation where the value of a tensor is not defined until it is run; this is because the value is dependent on data fed to the graph at running time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3GjCHShI468O",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "a = tf.placeholder(dtype=tf.int32, shape=(), name='input')\n",
        "b = tf.constant(-1, name='b')\n",
        "c = tf.add(a, b, name='c')\n",
        "\n",
        "with tf.Session() as session:\n",
        "  print(session.run(c, feed_dict={a: 3}))\n",
        "  print(session.run(c, feed_dict={a: 10}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEeJPNHFgtlW"
      },
      "source": [
        "We used a `tf.placeholder`. These are tensors that have no value or computation associated to them by default, instead they simply take data so this data can be computed on by the rest of the graph.\n",
        "\n",
        "Note that, at the same time, **any tensor may be fed with some data**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "88G0QbH44DWX"
      },
      "source": [
        "Another strength of the computation graph approach is that some nodes may be stateful. The most common stateful node is a *variable*. **A variable is a tensor that remembers its value between run calls**. This also means **it must be initialized**. \n",
        "\n",
        "In the following example `a` will be a variable. We also define an `inc` operation that increments the value of `a` by 1 each time this operation is run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dym9zktt6MkU",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "a = tf.get_variable('counter', shape=(), dtype=tf.int64)\n",
        "inc = tf.assign(a, a+1)\n",
        "init_op = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run(init_op)     # Sets an initial value for a.\n",
        "  print(session.run(a))    # By default, this is 0.\n",
        "  print(session.run(a))\n",
        "  session.run(inc)\n",
        "  session.run(inc)\n",
        "  print(session.run(a))    # We see the variable was incremented (twice).\n",
        "  # If you were to print the output of inc, you see that it actually\n",
        "  # returns the value of a post-increment. This is a convenience feature\n",
        "  # of tf.assign().\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6gcSLObKiB2-"
      },
      "source": [
        "Statefulness is highly relevant to us since the weights of our machine learning models are stored as variables and are updated by some operations in `session.run` calls during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SMndofivB1UA"
      },
      "source": [
        "### (OPTIONAL) Control dependencies and Race conditions\n",
        "\n",
        "*These topics do not often come up when training simple neural networks, but they are core concepts of tensorflow and you should be familiar with them.*\n",
        "\n",
        "With the introduction of stateful graph components we need to revisit the rule that tensorflow only executes the minimal set of operations required by a `run()` call. **Try predicting the output of the following cell.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CcfLCBN6B1wg",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "x = tf.get_variable(\"x\", shape=(), initializer=tf.zeros_initializer())\n",
        "assign_x = tf.assign(x, 10.0)\n",
        "z = x + 1.0\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as session:\n",
        "  session.run(init)\n",
        "  print(session.run(z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2GG5vevHC2Ln"
      },
      "source": [
        "From tensorflow's perspective,\n",
        "\n",
        "* There is a variable `x`, which starts with value 0,\n",
        "* `z` is always `x+1`,\n",
        "* with `assign_x` you can set the value of `x` to 10.\n",
        "\n",
        "So if you simply ask for the value of `z`, tensorflow evaluates the minimal subset of the graph it needs and reports that `z = 0 + 1`.  This is reflected in the graph as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWragQhLC2Sq",
        "colab": {}
      },
      "source": [
        "show_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9j_eg2vUC2ZA"
      },
      "source": [
        "If you want `x` incremented by 10 before using it to calculate `z`, you need to tell tensorflow.  You can do so by specifying `assign_x` as a (control_)dependency of z."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5ZPI-FIqDdKD",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "x = tf.get_variable(\"x\", shape=(), initializer=tf.zeros_initializer())\n",
        "assign_x = tf.assign(x, 10.0)\n",
        "with tf.control_dependencies([assign_x]):\n",
        "  z = x + 1.0\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as session:\n",
        "  session.run(init)\n",
        "  print(session.run(z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2rvcRUhGDdQu"
      },
      "source": [
        "To be precise, `tf.control_dependencies` ensures all operations / tensors passed to it are run before running the the operations defined inside its body."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9jIrvWWzFMZN"
      },
      "source": [
        "The other rule to keep in mind is that **Tensorflow is inherently parallel.** If there are computation subgraphs that do not depend on each other, they can -- and likely will be -- evaluated in parallel. We use the same generic example to illustrate this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yyN-AnRfGABu",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "x = tf.get_variable(\"x\", shape=(), initializer=tf.zeros_initializer())\n",
        "z = x + 1.0\n",
        "assign_x10 = tf.assign(x, 10.0)\n",
        "assign_x5 = tf.assign(x, 5.0)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as session:\n",
        "  session.run(init)\n",
        "  for _ in range(10):\n",
        "    _, _, z_val = session.run([assign_x10, assign_x5, z])\n",
        "    print(z_val)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "68duXIjaFMis"
      },
      "source": [
        "We can see that `z` can take various values: its value will depend on what order the different operations get run -- which we don't control. (If you do not see different values, re-run the cell until you do.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "akMRszLOMFXi"
      },
      "source": [
        "The lesson is that **if you care about the order of otherwise independent operations, you must be explicit about this**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "woBAfFv7h5ua"
      },
      "source": [
        "### Exercise: \"Interactive Tensorflow Summing Machine\"\n",
        "\n",
        "Write a tensorflow graph which keeps a running sum of the integers passed to it through a `feed_dict`. To make sure it works feed the machine a few numbers, printing the cumulative sum after each step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PhmThcmDh6FR",
        "colab": {}
      },
      "source": [
        "#@title Your Code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "9jTyd1LrilBt",
        "colab": {}
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "tf.reset_default_graph()\n",
        "cumulative_sum = tf.get_variable('sum', shape=(), dtype=tf.int64)\n",
        "to_add = tf.placeholder(dtype=tf.int64, shape=(), name='input')\n",
        "add = tf.assign(cumulative_sum, cumulative_sum + to_add)\n",
        "init_op = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run(init_op)  # Sets an initial value for a.\n",
        "  for i in range(1, 6):\n",
        "    print('cumulative sum={}; adding {}.'.format(session.run(cumulative_sum), i))\n",
        "    session.run(add, feed_dict={to_add: i})\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XvriNEgIAbms"
      },
      "source": [
        "## A word on tensorflow tensor shapes\n",
        "\n",
        "Tensors in Tensorflow have **static and dynamic shape**.\n",
        "\n",
        "* Static shape information is known or can be deduced at graph construction time,\n",
        "* Dynamic shape information is only available when data is available.\n",
        "\n",
        "**Static shape may be and is often only partially defined**. For example, we may know that our model expect a batch of examples, each of shape `2 x 2`, but not how large these batches are. This will allow us to feed the computation graph with batches of any size. Once data is fed the tensors will have a known **dynamic shape**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dceGjHt6Ab6y",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "inputs = tf.placeholder(dtype=tf.int32, shape=(None, 2, 2), name='input')\n",
        "print('static shape:', inputs.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KOZU2rgKBQRl"
      },
      "source": [
        "We pass `None` for axes that we do not know the static length of when specifying a shape. When a tensor or its shape is printed, this is denoted by a question mark, `?`, as seen above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rW8LjIbXhPKG"
      },
      "source": [
        "**Bug-alert:**  Be careful not to confuse passing `(None)` vs `(None,)` as a desired shape. The next cell illustrates the consequences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FtF9B5mngHMt",
        "colab": {}
      },
      "source": [
        "inputs_1 = tf.placeholder(dtype=tf.int32, shape=(None), name='input')\n",
        "inputs_2 = tf.placeholder(dtype=tf.int32, shape=(None,), name='input')\n",
        "print(inputs_1.shape)   # Shape that we know nothing about, not even rank.\n",
        "print(inputs_2.shape)   # Tensorflow will assert that the tensor is of rank 1,\n",
        "                        # albeit with unknwon length."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2xvgx50cf3B2"
      },
      "source": [
        "The static shape information is used to\n",
        "\n",
        "* verify operations make sense (think matrix multiplication),\n",
        "* infer the static shape of tensors defined through operations (so they can also be checked) .\n",
        "\n",
        "**Example**\n",
        "\n",
        "1. We take `batch (?) x 2 x 2`-shaped tensors, flatten each example in the batch to be a vector of length `4`. Tensorflow will infer the shape of the flattened tensor automatically.\n",
        "2. Then we multiply the now `? x 4`-shaped tensor with a vector. Tensorflow will only allow this to happen if the vector is of length 4, as otherwise the operation makes no sense.\n",
        "\n",
        "(In practice the `tf.matmul` operation we use does not accept vectors, so we will use a `4 x 1` matrix instead.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s9ANUmVrB7qY",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "inputs = tf.placeholder(dtype=tf.int32, shape=(None, 2, 2), name='input')\n",
        "flat_inputs = tf.contrib.layers.flatten(inputs)\n",
        "print('flat_inputs static shape', flat_inputs.shape)\n",
        "\n",
        "result = tf.matmul(flat_inputs, tf.constant([[0], [1], [2], [3]], name='ok'))\n",
        "print('result static shape', result.shape)\n",
        "\n",
        "# Uncomment and run to see\n",
        "#\n",
        "# ValueError: Dimensions must be equal, but are 4 and 3 for 'MatMul_4'\n",
        "# (op: 'MatMul') with input shapes: [?,4], [3,1].\n",
        "#\n",
        "#tf.matmul(flat_inputs, tf.constant([[0], [1], [2]], name='shape_mismatch'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TlHbOikVBvwo"
      },
      "source": [
        "It happens sometimes (e.g. for custom operations) that tensorflow is not be able to infer the static shape of the resulting tensor.  f you know the expected shape, you can explicitly set it using `tensor.set_shape()`. This will allow tensorflow to infer and check later shapes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bolN-5BRF2Pf"
      },
      "source": [
        "Finally, let us try working with the dynamic shape of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x9U6SsqVBQXc",
        "colab": {}
      },
      "source": [
        "print('dynamic shape:', tf.shape(inputs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4sXdJmSLF1l-"
      },
      "source": [
        "The **dynamic shape itself is a tensor** and may (only) be evaluated or computed with once the graph is run in a session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3tFB0_e9GDqi",
        "colab": {}
      },
      "source": [
        "shape = tf.shape(inputs)\n",
        "num_total_elements = tf.reduce_prod(shape)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  print(session.run([shape, num_total_elements], feed_dict={\n",
        "      inputs: np.array(np.random.random((3, 2, 2)))\n",
        "  }))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R05v98YcrjeR"
      },
      "source": [
        "### Broadcasting\n",
        "\n",
        "Tensorflow automatically broadcasts operations, similarly to `numpy`. We covered broadcasting in detail in the `numpy` colab. Here we include three common examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yVAhM_F0qIjP",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "a = tf.constant([[1, 2, 3], [4, 5, 6]], name='a')\n",
        "c = a - 1   # `1` is first turned into a constant,\n",
        "            # then broadcast across the full tensor\n",
        "\n",
        "with tf.Session() as session:\n",
        "    print(session.run(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wj449M26rj9Z",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "a = tf.constant([[1, 2, 3], [4, 5, 6]], name='a')\n",
        "b = tf.constant([1000, 100, 10], name='b')\n",
        "c = a + b\n",
        "# a: 2 x 3\n",
        "# b:     3\n",
        "# --> b is copied over across the first axis to calculate c.\n",
        "\n",
        "with tf.Session() as session:\n",
        "    print(session.run(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0eC_cWM1s6Ub",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "a = tf.constant([[1, 2, 3], [4, 5, 6]], name='a')\n",
        "b = tf.constant([100, 10], name='b')\n",
        "# a: 2 x 3\n",
        "# b:     2\n",
        "# --> a and b are not compatible;\n",
        "#a + b    # Raises an error.\n",
        "\n",
        "# Instead, b can be defined as [[100], [10]] so that\n",
        "# a: 2 x 3\n",
        "# b: 2 x 1\n",
        "# --> b is copied across the last axis.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X_FfiXzOqb6R"
      },
      "source": [
        "**As a general rule of thumb**\n",
        "\n",
        "* use broadcasting in the simple cases\n",
        "* prefer explicit broadcasting in complex situations.\n",
        "\n",
        "This will result in code that is **easier to read** and has **fewer bugs**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7-_uTExc6M7e"
      },
      "source": [
        "## Building a simple network with Sonnet\n",
        "\n",
        "Instead of building our neural networks in plain Tensorflow, we use the [sonnet](https://github.com/deepmind/sonnet) library.\n",
        "\n",
        "**Sonnet uses an object-oriented approach, similar to other frameworks (like Keras or PyTorch).**\n",
        "\n",
        "* This allows modules to be created, which define the forward pass of some computation. \n",
        "* Modules are ‘called’ with some input Tensors, which adds ops to the Graph and returns output Tensors.\n",
        "\n",
        "We call this a **configure-then-connect principle**, which allows for easy reuse of complex modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vaXAee8c_VwJ",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()  # You can always clear the current graph and\n",
        "                          # add exactly what you need to it."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_JX0ugUkl7dA"
      },
      "source": [
        "Start by creating a Linear module (dense layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bXRJB-UN9QgM",
        "colab": {}
      },
      "source": [
        "linear = snt.Linear(output_size=5)\n",
        "linear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nv4ROlyl9Qms"
      },
      "source": [
        "Our input will be batches of 2-long vectors, and we will feed that data to the graph using `feed_dict`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mzMXfwp0_YeT",
        "colab": {}
      },
      "source": [
        "inputs_placeholder = tf.placeholder(tf.float32, shape=(None, 2), name='inputs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hQO7qLZM_Yrb"
      },
      "source": [
        "As in tensorflow, we \"call\" the module on the tensor that we want it to compute on. This yields a tensor, the output of the calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1_4Kmhdp_8jP",
        "colab": {}
      },
      "source": [
        "pre_activations = linear(inputs_placeholder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4wgBGo-f_8rI"
      },
      "source": [
        "To complete our model, we apply a ReLU non-linearity and add a final linear layer with just 1 output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8pKD3uf9_Y1u",
        "colab": {}
      },
      "source": [
        "activations = tf.nn.relu(pre_activations)\n",
        "outputs = snt.Linear(output_size=1)(activations)\n",
        "outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TH0GimMtsgqZ"
      },
      "source": [
        "We drop the final singleton axis so that `outputs` becomes a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nn8wiKbAshd-",
        "colab": {}
      },
      "source": [
        "outputs = tf.squeeze(outputs, axis=-1)\n",
        "outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xst87vC7kaV0"
      },
      "source": [
        "Let's see the graph we built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KJvV-Mggka2s",
        "colab": {}
      },
      "source": [
        "show_graph()   # With no arguments show_graph() shows the default graph."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9H3q1yfMkewp"
      },
      "source": [
        "You can explore the exact set of tensorflow operations that were created the sonnet code by expanding colored boxes. **We can verify that each linear layer implements $WX+b$ for $X$ inputs and $W$ weights and $b$ bias with basic tensorflow operations**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0I76TX0ql3Q8"
      },
      "source": [
        "Let's pass some data through our model. We will use the data generating function we wrote in the numpy colab. (It is redefined at the top of this colab)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dugx7fxknxsV",
        "colab": {}
      },
      "source": [
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tCtNXgVAke4Q",
        "colab": {}
      },
      "source": [
        "inputs_np, unused_labels_np = get_data(num_examples=8)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run(init_op)  # Initializes the weights in the network.\n",
        "  outputs_np = session.run(outputs, feed_dict={\n",
        "      inputs_placeholder: inputs_np,\n",
        "  })\n",
        "\n",
        "outputs_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZfkWabTike_i"
      },
      "source": [
        "You can rerun the above cell to see the output on new and new batches. The one thing that now remains is...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LPlrr6NvqhjE"
      },
      "source": [
        "## Training a tensorflow model\n",
        "\n",
        "This is the same with or without sonnet. \n",
        "\n",
        "We will start by\n",
        "\n",
        "1. Making the correct labels available to the graph,\n",
        "2. Using these to define and calculate the loss on the output of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5NjyuVM0nzVC",
        "colab": {}
      },
      "source": [
        "labels_placeholder = tf.placeholder(tf.float32, shape=(None,), name='labels')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WM5liEzKTa0q"
      },
      "source": [
        "Here we will simply regress onto the labels with the squared loss. (It would be better to calculate a cross entropy.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dveVOLfC9GKf",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('element_wise_loss'):\n",
        "  loss = tf.square(labels_placeholder - outputs)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9lTQIdr79e-_"
      },
      "source": [
        "The loss tensor now calculates the loss per example. We want one scalar to optimize:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pT_esW_H9Veo",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(loss, name='batch_mean_loss')\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f6i4I7WInzlO"
      },
      "source": [
        "We can verify on the graph that everything is as expected. The `name_scope` and `name` instructions make the graph easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AYrxqaptsnA-",
        "colab": {}
      },
      "source": [
        "show_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Ad9LzFJsnHk"
      },
      "source": [
        "We need to tell the computation graph that we want to minimize this loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mn5gwBw5s2kq",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "train_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iLQ37jcduDwE"
      },
      "source": [
        "**It is worth noting here the effect of this call on the graph.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bqEc0SO-totM",
        "colab": {}
      },
      "source": [
        "show_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BCcYLuZms1-B"
      },
      "source": [
        "The minimization call added\n",
        "\n",
        "* gradient calculation operations\n",
        "* operations that update the weights based on these gradients.\n",
        "\n",
        "In fact, **we could have built the graph corresponding to `minimize()` manually** by\n",
        "\n",
        "* calculating the gradients of the loss with respect to the weights with the `tf.gradients(loss, [list of weights])` operation,\n",
        "* potentially scaling these gradients and adding them to the existing weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JSOTFgNDnxQv"
      },
      "source": [
        "By running the returned `train_op`, we take one gradient step, fitting the data just a bit better. Let's do this! But first some setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g1rq6u6JHuYV",
        "colab": {}
      },
      "source": [
        "# Get some training data, and plot it. This is based on earlier exercises.\n",
        "inputs_np, true_labels_np = get_data(num_examples=128)\n",
        "plot_nxor_data(inputs_np, true_labels_np, title='Train data')\n",
        "\n",
        "# Show some statistics that can help with debugging\n",
        "print('Mean label on train data:', np.mean(true_labels_np))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-1rqXbD66xH4",
        "colab": {}
      },
      "source": [
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kep9Tdjln0Ki"
      },
      "source": [
        "**The final training script.**  \n",
        "\n",
        "This cell contains all training and some reporting code. For now you can just run it, but for the next exercise you will have to understand it.\n",
        "\n",
        "*Note that sometimes we can get a bad weight initialization, but in a few runs you can easily get below 5% error.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HxIP3cY4kfIA",
        "colab": {}
      },
      "source": [
        "RECORD_PERIOD = int(1e3)\n",
        "\n",
        "training_steps = 10000   #@param {'type': 'integer'}\n",
        "\n",
        "print('Losses:')\n",
        "with tf.Session() as session:\n",
        "  session.run(init_op)  # Initializes the weights in the network.\n",
        "\n",
        "  for i in range(training_steps):\n",
        "    _, loss_np = session.run(\n",
        "        [train_op, loss],\n",
        "        feed_dict={\n",
        "            inputs_placeholder: inputs_np,\n",
        "            labels_placeholder: true_labels_np,\n",
        "    })\n",
        "    if (i % RECORD_PERIOD) == 0:\n",
        "      print(' ', loss_np)\n",
        "      if loss_np < 0.01:\n",
        "        print()\n",
        "        print('Loss hit threshold after {} steps, stopping.'.format(i))\n",
        "        break\n",
        "  \n",
        "  print()\n",
        "  # The model is ready to be evaluated. Fetch the predicted outputs.\n",
        "  predictions_np = session.run(outputs,\n",
        "      feed_dict={\n",
        "          inputs_placeholder: inputs_np,\n",
        "  })\n",
        "  # Actual label predictions given as {-1, +1}.\n",
        "  predictions_np[predictions_np <= 0] = -1\n",
        "  predictions_np[predictions_np > 0] = 1\n",
        "  # Prediction errors and plotting.\n",
        "  num_correct = np.count_nonzero(np.isclose(predictions_np, true_labels_np))\n",
        "  num_examples = true_labels_np.shape[0]\n",
        "  print('Prediction error:', (num_examples-num_correct)/num_examples)\n",
        "  plot_nxor_data(inputs_np, predictions_np, title='Predictions')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BA0DfXiDWVym"
      },
      "source": [
        "Notice that the prediction error calculation was inside the `with tf.Session()` context manager. This because **the graph state (including weights) is only maintained on a per session basis**. It is possible to save (and load) graphs, including their weights, with a [`tf.train.Saver`](https://www.tensorflow.org/api_docs/python/tf/train/Saver)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SJLoWp90ueo4"
      },
      "source": [
        "## Exercise:  Evaluate the trained model\n",
        "\n",
        "We have seen how to train the model -- that is -- we saw that the model can fit the training set well. But we are actually  interested in generalizing to new examples from the same data distribution.\n",
        "\n",
        "1. Define a training and a test dataset using our data generation function.\n",
        "2. Fit the training data using the model we defined above.\n",
        "3. Instead of reporting the prediction error only on the training set, also report it on the test set.\n",
        "4. Plot the predictions on the test set using the pre-defined plotting function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z-3LJCcXxSxO"
      },
      "source": [
        "For simplicity, the full model building code is included in the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0-i6rjzYXGa8",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Inputs.\n",
        "inputs_placeholder = tf.placeholder(tf.float32, shape=(None, 2), name='inputs')\n",
        "labels_placeholder = tf.placeholder(tf.float32, shape=(None,), name='labels')\n",
        "\n",
        "# All network and loss definition.\n",
        "activations = tf.nn.relu(\n",
        "    snt.Linear(output_size=5)(inputs_placeholder))\n",
        "outputs = tf.squeeze(\n",
        "    snt.Linear(output_size=1)(activations), axis=-1)\n",
        "loss = tf.reduce_mean(\n",
        "    tf.squared_difference(labels_placeholder, outputs))\n",
        "\n",
        "# Optimizer and initializer.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
        "train_op = optimizer.minimize(loss)\n",
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uYdMlXp6uehe",
        "colab": {}
      },
      "source": [
        "#@title Your Code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "nIDH0C6lWVku",
        "colab": {}
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "# The solution is very similar to the previous training script, except care\n",
        "# needs to be taken to have a separate train and test set.\n",
        "\n",
        "train_inputs_np, train_labels_np = get_data(num_examples=256)\n",
        "test_inputs_np, test_labels_np = get_data(num_examples=128)\n",
        "\n",
        "\n",
        "TRAINING_STEPS = int(2e4)\n",
        "RECORD_PERIOD = int(1e3)\n",
        "\n",
        "\n",
        "def _get_predictions(inputs):\n",
        "  predictions_np = session.run(outputs,\n",
        "      feed_dict={\n",
        "          inputs_placeholder: inputs,\n",
        "  })\n",
        "  # Actual label predictions given as {-1, +1}.\n",
        "  predictions_np[predictions_np <= 0] = -1\n",
        "  predictions_np[predictions_np > 0] = 1\n",
        "  return predictions_np\n",
        "\n",
        "\n",
        "def _get_error(predictions, true_labels):\n",
        "  num_correct = np.count_nonzero(np.isclose(predictions, true_labels))\n",
        "  num_examples = true_labels.shape[0]\n",
        "  return (num_examples-num_correct) / num_examples\n",
        "\n",
        "\n",
        "print('Losses:')\n",
        "with tf.Session() as session:\n",
        "  session.run(init_op)  # Initializes the weights in the network.\n",
        "\n",
        "  for i in range(TRAINING_STEPS):\n",
        "    _, loss_np = session.run(\n",
        "        [train_op, loss],\n",
        "        feed_dict={\n",
        "            inputs_placeholder: train_inputs_np,\n",
        "            labels_placeholder: train_labels_np,\n",
        "    })\n",
        "    if (i % RECORD_PERIOD) == 0:\n",
        "      print(' ', loss_np)\n",
        "      if loss_np < 0.01:\n",
        "        print()\n",
        "        print('Loss hit threshold after {} steps, stopping.'.format(i))\n",
        "        break\n",
        "  \n",
        "  print()\n",
        "  # The model is ready to be evaluated.\n",
        "  train_predictions = _get_predictions(train_inputs_np)\n",
        "  train_error = _get_error(train_predictions, train_labels_np)\n",
        "  \n",
        "  test_predictions = _get_predictions(test_inputs_np)\n",
        "  test_error = _get_error(test_predictions, test_labels_np)\n",
        "  \n",
        "  print('Train error:', train_error)\n",
        "  print('Test error:', test_error)\n",
        "  plot_nxor_data(test_inputs_np, test_predictions, title='Predictions')\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MAJnizTyrIan"
      },
      "source": [
        "## (Optional) Datasets\n",
        "\n",
        "So far we used a `feed_dict`s to pass data to the computation graph. Another, often more efficient solution is to have nodes in the graph read, maninpulate, and make data available.\n",
        "\n",
        "Tensorflow has a dedicated `tf.data` module.  Tensorflow's [Importing Data Guide](https://www.tensorflow.org/guide/datasets) guide is a great resource for learning about it. **Read this guide up to and including the \"Reading input data > Consuming NumPy arrays\"** section.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3nrz4qxB_CwD"
      },
      "source": [
        "### Exercise: define a tensorflow dataset\n",
        "\n",
        "1. Use the `get_data` function from before to generate a training dataset of 1000 examples and a test dataset of 500 examples.\n",
        "2. Using `from_tensor_slices()`, define a training and a test `tf.data.Dataset`.\n",
        "3. Ensure that the train data is (a) fully shuffled (b) can be iterated infinitely (c) is batched with a batch size of 64.\n",
        "4. We do not shuffle the test data and we only want to iterate it once. We still batch it up so that the amount of data we compute on is limited.\n",
        "\n",
        "**Write a function called `get_tf_dataset()` that returns a (`train_dataset, test_dataset`)-tuple according to these instructions.** Print the returned datasets in order to verify they are correctly defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pNOBmK79HTpD",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lksIuNH5_DjN",
        "colab": {}
      },
      "source": [
        "#@title Your Code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "XxX8XhTKAS-9",
        "colab": {}
      },
      "source": [
        "#@title Solution\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_data_np = get_data(1000)\n",
        "test_data_np = get_data(500)\n",
        "\n",
        "def get_tf_dataset():\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices(train_data_np)\n",
        "  train_dataset = train_dataset.shuffle(1000).repeat().batch(BATCH_SIZE)\n",
        "\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices(test_data_np)\n",
        "  test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "  \n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "print(get_tf_dataset())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3pxg1Tvj9l_X"
      },
      "source": [
        "We need to access the data as tensors. We can do so by asking for an iterator over the dataset. We use the simplest iterator, which simply iterates over the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t_MqBL1AOLve",
        "colab": {}
      },
      "source": [
        "train_dataset, test_dataset = get_tf_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rMCtoQalD6go",
        "colab": {}
      },
      "source": [
        "train_data_iter = train_dataset.make_one_shot_iterator()\n",
        "(train_inputs, train_labels) = train_data_iter.get_next()\n",
        "train_inputs, train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nO8DGVktHARQ",
        "colab": {}
      },
      "source": [
        "test_data = test_dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PZ9iRdHjD6nE"
      },
      "source": [
        "Now we can use `train_inputs` and `train_labels` like any other tensor. Each time we use them in a `session.run()` the tensor will hold a new batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "STpmjTfOEduK",
        "colab": {}
      },
      "source": [
        "def _print_some(np_array, descr):\n",
        "  print(descr + ':')\n",
        "  print('  shape: {}'.format(np_array.shape))\n",
        "  print('  first examples in batch: {}'.format(np_array[:4]))\n",
        "\n",
        "\n",
        "with tf.Session() as session:\n",
        "  # Train data.\n",
        "  for _ in range(2):\n",
        "    train_inputs_np, train_labels_np = session.run([train_inputs, train_labels])\n",
        "    _print_some(train_inputs_np, 'train_inputs')\n",
        "    _print_some(train_labels_np, 'train_labels')\n",
        "    print()\n",
        "  \n",
        "  # Test data.\n",
        "  test_inputs_np, test_labels_np = session.run(test_data)\n",
        "  _print_some(test_inputs_np, 'test_inputs')\n",
        "  _print_some(test_labels_np, 'test_labels')\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hZckeyEaTgO8"
      },
      "source": [
        "We defined the test dataset to supply data for exacly one full iteration of the test dataset. We can fetch data until tensorflow lets us know there is no more data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QMFducB2Tnbo",
        "colab": {}
      },
      "source": [
        "with tf.Session() as session:\n",
        "  counter = 0\n",
        "  while True:\n",
        "    try:\n",
        "      test_inputs_np, test_labels_np = session.run(test_data)\n",
        "      counter += 1\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break\n",
        "  print('Counted {} batches of test examples.'.format(counter))\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M2nTc8Rxzytz"
      },
      "source": [
        "The `make_one_shot_iterator()` function returns an iterator that, when exhausted, cannot be restarted. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "22XTfhplEd0s"
      },
      "source": [
        "There are many utility functions in the `tf.data` both for reading in and manipulating data; chances are, whatever you would like to do it is already available there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8sUCWDkSrS2s"
      },
      "source": [
        "### Queues\n",
        "\n",
        "In earlier versions of tensorflow datasets had to be manipulated with so called [Queues](https://www.tensorflow.org/api_guides/python/threading_and_queues). They allowed data loading and preprocessing to be asynchronous, making the input pipeline faster. Their use for input pipelines is now deprecated, if you are interested in increasing the performance of your input pipeline read the [official guide on this topic](https://www.tensorflow.org/performance/datasets_performance).\n",
        "\n",
        "Queues are still used for pushing data between different threads, potentially on different machines, but we will not cover them in this lab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BtoJu2JQufKa"
      },
      "source": [
        "## The Power of Sonnet\n",
        "\n",
        "The Sonnet library has two key selling points:\n",
        "\n",
        "* Complex networks are easily reused.\n",
        "* Variable sharing is handled transparently by automatically reusing variables on subsequent calls to the same module. \n",
        "\n",
        "We will now see these features in action.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1WJZFNUPJfCW"
      },
      "source": [
        "We start by defining a sonnet module corresponding to the classifier we have been working with. The section on [defining your own submodules](https://deepmind.github.io/sonnet/#defining-your-own-modules) in the sonnet documentation is both helpful and precise. The key points are:\n",
        "\n",
        "* Inherit from snt.AbstractModule\n",
        "* Call superclass constructor\n",
        "* Implement the `_build()` method\n",
        "\n",
        "The `_build()` method is meant to construct all computation graph corresponding to this module. It takes as argument the inputs to the module, and returns the outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YlUQsYkdq1Om",
        "colab": {}
      },
      "source": [
        "class MySimpleModule(snt.AbstractModule):\n",
        "\n",
        "  def __init__(self, num_hidden, nonlinearity=tf.nn.relu,\n",
        "               name=\"my_simple_module\"):\n",
        "    super(MySimpleModule, self).__init__(name=name)\n",
        "    self._num_hidden = num_hidden\n",
        "    self._nonlinearity = nonlinearity\n",
        "   \n",
        "  def _build(self, inputs):\n",
        "    # Inputs has shape batch_size x ?.\n",
        "    pre_activations = snt.Linear(output_size=self._num_hidden)(inputs)\n",
        "    activations = self._nonlinearity(pre_activations)\n",
        "    outputs = snt.Linear(output_size=1)(activations)\n",
        "    return tf.squeeze(outputs, axis=-1)  # Shape: [batch_size].\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c02sphDjlqkB"
      },
      "source": [
        "Aside: since this module is simply a sequence of other modules and tensorflow ops (e.g. the non-linearity), the module could have been made using the `snt.Sequential()` wrapper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NArC4JAtOl7I"
      },
      "source": [
        "We can make a particular instance of the module we defined like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NECiDI2bOnRc",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "model = MySimpleModule(num_hidden=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IcYsy2PDMZRQ"
      },
      "source": [
        "No graph has actually been created so far, since only the constructor of the class ran. Let's connect this module to the training data.\n",
        "\n",
        "*Note that while it is encouraged to only create graph in the `_build()` method, some sonnet modules may already do so in their constructor.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bQGjSNnGObv2",
        "colab": {}
      },
      "source": [
        "train_dataset, test_dataset = get_tf_dataset()\n",
        "train_inputs, train_labels = train_dataset.make_one_shot_iterator().get_next()\n",
        "train_ouputs = model(train_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_6TgD66tP3Zb"
      },
      "source": [
        "The connection triggered the `_build()` function and we can see the graph corresponding to the model is built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M5Fa4BhDP3fQ",
        "colab": {}
      },
      "source": [
        "show_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X1y4JiTqJcvl"
      },
      "source": [
        "The beauty of sonnet is that we can **connect the same `model` instance to the test data tensor and it will automatically share variables**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0cqTPzOHRDpO",
        "colab": {}
      },
      "source": [
        "test_inputs, test_labels = test_dataset.make_one_shot_iterator().get_next()\n",
        "test_outputs = model(test_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pr39gvUaX8O1"
      },
      "source": [
        "Of course creating another instance will not share variables. Can you tell, based on the graph (not considering the names) which modules share weights?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oWSEVHdkYB8T",
        "colab": {}
      },
      "source": [
        "unshared_test_outputs = MySimpleModule(num_hidden=5, name='unshared_simple_module')(test_inputs)\n",
        "show_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lAdu7dhvRDxb"
      },
      "source": [
        "The fact that `train_outputs` and `test_outputs` use shared variables means that training based on `train_outputs` will improve the quality of `test_ouputs` as well. We show this next.\n",
        "\n",
        "We base the training script here based on our previous one. Some modifications are required:\n",
        "\n",
        "* The references to the dataset must be updated. We do not use `feed_dicts`, but we must take care to run `test_outputs` or `train_outputs`.\n",
        "* In order to get the true (test) labels, we need to run the `test_labels` tensor.\n",
        "* We need to iterate over the full test dataset.\n",
        "\n",
        "Another change is that now each training step uses a different batch of data, while our earlier version used the full (smaller) dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P4qhLEYPJc4r",
        "colab": {}
      },
      "source": [
        "# CHANGED HERE:\n",
        "loss = tf.reduce_mean(tf.squared_difference(train_labels, train_ouputs))\n",
        "\n",
        "# Optimizer and initializer.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
        "train_op = optimizer.minimize(loss)\n",
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AjmiYrqOq1W1",
        "colab": {}
      },
      "source": [
        "TRAINING_STEPS = int(2e4)\n",
        "RECORD_PERIOD = int(1e3)\n",
        "\n",
        "def _num_correct(predictions_np, true_labels_np):\n",
        "  # Actual label predictions given as {-1, +1}.\n",
        "  predictions_np[predictions_np <= 0] = -1\n",
        "  predictions_np[predictions_np > 0] = 1\n",
        "  # Count correct predictions.\n",
        "  return np.count_nonzero(np.isclose(predictions_np, true_labels_np))\n",
        "\n",
        "  \n",
        "print('Losses:')\n",
        "with tf.Session() as session:\n",
        "  session.run(init_op)  # Initializes the weights in the network.\n",
        "\n",
        "  for i in range(TRAINING_STEPS):\n",
        "    _, loss_np = session.run([train_op, loss])  # CHANGED HERE.\n",
        "    if (i % RECORD_PERIOD) == 0:\n",
        "      print(' ', loss_np)\n",
        "  \n",
        "  print()\n",
        "  # The model is ready to be evaluated. Fetch the predicted outputs.\n",
        "  num_correct = 0\n",
        "  num_elements = 0\n",
        "  while True:\n",
        "    try:\n",
        "      # CHANGES HERE.\n",
        "      predictions_np, true_labels_np = session.run([test_outputs, test_labels])\n",
        "      num_elements += predictions_np.shape[0]\n",
        "      num_correct += _num_correct(predictions_np, true_labels_np)\n",
        "    except tf.errors.OutOfRangeError:\n",
        "      break\n",
        "  print('The prediction error on the test set:',\n",
        "        (num_elements - num_correct) / num_elements)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PorU6KbWWxg0"
      },
      "source": [
        "We will see another convenient feature of Sonnet when working with generative models in the VAE and GAN lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0jXX5yAJrIil"
      },
      "source": [
        "## Debugging Tensorflow\n",
        "\n",
        "Debugging tensorflow code and models can be challenging when compared to debugging 1) simple python code or even 2) other machine learning code. This is due to the separate building and running phases* of tensorflow:\n",
        "\n",
        "* You cannot simply just stop the computation midway in a `run()` call and inspect what is going on. **\n",
        "* If an error is only revealed in a `session.run()` call, Tensorflow may often be unable to point you to the python code that generated the offending operation.\n",
        "* Race conditions may occur. These can be hard to detect because the race condition may only occur very very infrequently.\n",
        "\n",
        "In this section we list some practical advice to debugging tensorflow.\n",
        "\n",
        "<small>*&ast;Tensorflow's Eager mode removes this separation, making debugging simpler.</small><br />\n",
        "<small>*&ast;*&ast;There is a [tensorflow debugger](https://www.tensorflow.org/programmers_guide/debugger) that tries to address this problem.*</small>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_CiUuqj3rH5I"
      },
      "source": [
        "* **Check your shapes**. It is possible that something is not of the shape you expect, but due to broadcasting the graph still computes something -- but not what you want.\n",
        "* **Check the graph with tensorboard**. Does it do what you wanted it to?\n",
        "* **Print and/or assert values of tensors**. While you cannot stop your graph mid-computation, you can print the values going through them. Unfortunately this [does not currently work](https://www.tensorflow.org/api_docs/python/tf/Print) in notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NTvYunx7-J7u"
      },
      "source": [
        "## Not covered: Control Flow\n",
        "\n",
        "In tensorflow you can define logical operations such as conditionals, loops, etc. In fact, Tensorflow is Turing-complete. We do not cover them as these operations are not usually required for training neural nets, and it is better to avoid them unless really needed due their added compexity.\n"
      ]
    }
  ]
}