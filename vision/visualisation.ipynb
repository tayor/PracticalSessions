{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visualisation_solution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nassma2019/PracticalSessions/blob/master/vision/visualisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J7p406abzgl",
        "colab_type": "text"
      },
      "source": [
        "## Part II: Visualise saliency maps\n",
        "- Import an already trained baseline model.\n",
        "- Visualise the gradients of class probabilities w.r.t inputs to obtain saliency maps.\n",
        "- Generate inputs that maximise class probabilities.\n",
        "\n",
        "#### Exercises:\n",
        "\n",
        "1. Retrieve the gradient of the most probable class w.r.t. to input image using `tf.gradients` and plot saliency maps.\n",
        "2. Iterate the above and take steps into the direction of this gradient starting from a test image.\n",
        "\n",
        ">*  The gradient indicates how to modify the input image to make it look more like the class it is taken from, according to the network.\n",
        ">* Note that the network weights are kept fixed, only the input is transformed, i.e. we retrieve gradients, but we never apply them to the network weights.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhWI4Pix5GJw",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0VvPXmYKp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# we will use Sonnet on top of TF \n",
        "!pip install -q dm-sonnet\n",
        "import sonnet as snt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Plotting library.\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "from skimage import data, color\n",
        "from skimage.transform import rescale, resize, downscale_local_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xlKHOLbhvY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset graph\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c0b2N7PZamq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display function\n",
        "class_mapping = [u'airplane', u'automobile', u'bird', u'cat', u'deer', \n",
        "                 u'dog', u'frog', u'horse', u'ship', u'truck']\n",
        "def gallery(maps, imgs, pclass, gt, scale=4.0):\n",
        "  num_images= maps.shape[0]\n",
        "  maps = np.abs(maps).mean(axis=-1)\n",
        "  ff, axes = plt.subplots(2, num_images,\n",
        "                          subplot_kw={'xticks': [], \n",
        "                                      'yticks': []})\n",
        "  for i in range(0, num_images):\n",
        "    tt_pred = class_mapping[pclass[i]]\n",
        "    tt_gt = class_mapping[gt[i]]\n",
        "    mm = maps[i]/np.amax(maps[i])\n",
        "    mm_rescale = rescale(mm, scale)                         \n",
        "    axes[0,i].imshow(mm_rescale)\n",
        "    img = (imgs[i]+1.0)/2.0\n",
        "    img_rescale = rescale(img, scale)\n",
        "    axes[1,i].imshow(img_rescale)\n",
        "    plt.setp(axes[0,i].get_xticklabels(), visible=False)\n",
        "    plt.setp(axes[0,i].get_yticklabels(), visible=False)\n",
        "    axes[0,i].set_title('pred={}'.format(tt_pred))\n",
        "    axes[1,i].set_title('gt={}'.format(tt_gt))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH0yiib_z4R8",
        "colab_type": "text"
      },
      "source": [
        "### Copying the pretrained weights of baseline model on the virtual machine\n",
        "- we download all three files to the Colab virtual machine:\n",
        "- we will load a model with the same architecture that you defined earlier, but fully trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cubpPmHgECbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/nassma2019/PracticalSessions/blob/master/vision/baseline/baseline.ckpt.data-00000-of-00001?raw=true -O baseline.ckpt.data-00000-of-00001\n",
        "!wget https://github.com/nassma2019/PracticalSessions/blob/master/vision/baseline/baseline.ckpt.index?raw=true -O baseline.ckpt.index\n",
        "!wget https://github.com/nassma2019/PracticalSessions/blob/master/vision/baseline/checkpoint?raw=true -O checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g16XweXs2Uq",
        "colab_type": "text"
      },
      "source": [
        "### Get dataset to be used for visualisation\n",
        "- Cifar-10 equivalent of MNIST for natural RGB images\n",
        "- 60000 32x32 colour images in 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
        "- train: 50000; test: 10000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g_EOx07s1XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "# (down)load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHAggitWu94_",
        "colab_type": "text"
      },
      "source": [
        "### Retrieve batches from the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZofMjOuUEOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define dimension of the batches to sample from the datasets\n",
        "BATCH_SIZE_TEST = 5 #@param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO1xULtaWqR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "batched_dataset_test = dataset_test.repeat().batch(BATCH_SIZE_TEST)\n",
        "iterator_test = batched_dataset_test.make_one_shot_iterator() \n",
        "(batch_test_images, batch_test_labels) = iterator_test.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IqxUPlmtLJX",
        "colab_type": "text"
      },
      "source": [
        "### Model on which we will run the visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2scBoc09ZsO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Baseline(snt.AbstractModule):\n",
        "  \n",
        "  def __init__(self, num_classes, name=\"baseline\"):\n",
        "    super(Baseline, self).__init__(name=name)\n",
        "    self._num_classes = num_classes\n",
        "    self._output_channels = [\n",
        "        64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n",
        "        ]\n",
        "    self._num_layers = len(self._output_channels)\n",
        "\n",
        "    self._kernel_shapes = [[3, 3]] * self._num_layers  # All kernels are 3x3.\n",
        "    self._strides = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n",
        "    self._paddings = [snt.SAME] * self._num_layers\n",
        "   \n",
        "  def _build(self, inputs, is_training=None, test_local_stats=False):\n",
        "    net = inputs\n",
        "    # instantiate all the convolutional layers \n",
        "    layers = [snt.Conv2D(name=\"conv_2d_{}\".format(i),\n",
        "                         output_channels=self._output_channels[i],\n",
        "                         kernel_shape=self._kernel_shapes[i],\n",
        "                         stride=self._strides[i],\n",
        "                         padding=self._paddings[i],\n",
        "                         use_bias=True) for i in xrange(self._num_layers)]\n",
        "    # connect them to the graph, adding batch norm and non-linearity\n",
        "    for i, layer in enumerate(layers):\n",
        "      net = layer(net)\n",
        "      bn = snt.BatchNorm(name=\"batch_norm_{}\".format(i))\n",
        "      net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n",
        "      net = tf.nn.relu(net)\n",
        "\n",
        "    net = tf.reduce_mean(net, reduction_indices=[1, 2], keepdims=False,\n",
        "                         name=\"avg_pool\")\n",
        "\n",
        "    logits = snt.Linear(self._num_classes)(net)\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZzlpO0oJFZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scUEks38XHQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test preprocessing: only scale to [-1,1].\n",
        "def test_image_preprocess():\n",
        "  def fn(image):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = image * 2.0 - 1.0\n",
        "    return image\n",
        "  return fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c68u4b86uNb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the model \n",
        "with tf.variable_scope(\"baseline\"):\n",
        "  model = Baseline(num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grtPyN7QgIsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect the model to data\n",
        "preprocess_op = test_image_preprocess()\n",
        "batch_test_images = preprocess_op(batch_test_images)\n",
        "test_predictions = model(batch_test_images, is_training=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWtWWr8xgSCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create saver to restore the pre-trained model\n",
        "# First remove the scope name from variables name, since the name in the checkpoint doesn't include it\n",
        "var_list = snt.get_variables_in_scope(\"baseline\", \n",
        "                                      collection=tf.GraphKeys.GLOBAL_VARIABLES)  \n",
        "var_map = {}\n",
        "for i in range(0, len(var_list)):\n",
        "  name = var_list[i].name[len(\"baseline/\"):-2]\n",
        "  var_map[name] = var_list[i]\n",
        "  \n",
        "saver = tf.train.Saver(var_map, reshape=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLtMkv8htou9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For evaluation, we look at top_k_accuracy since it's easier to interpret; normally k=1 or k=5\n",
        "def top_k_accuracy(k, labels, logits):\n",
        "  in_top_k = tf.nn.in_top_k(predictions=tf.squeeze(logits), \n",
        "                            targets=tf.squeeze(tf.cast(labels, tf.int32)), k=k)\n",
        "  return tf.reduce_mean(tf.cast(in_top_k, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-FlGBzUKC1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_acc = top_k_accuracy(1, batch_test_labels, test_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6IIjdk8LlAq",
        "colab_type": "text"
      },
      "source": [
        "### Visualise saliency maps\n",
        "\n",
        "- We retrieve gradients w.r.t. inputs to obtain a saliency map over the input pixels, i.e. to understand which pixels in an image caused a certain output logit to be maximised.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu5IDKJTjx_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Exercise.\n",
        "# Get the maximum output prediction\n",
        "# maximum_prediction =  ############## YOUR CODE ##############\n",
        "\n",
        "# Get the gradient w.r.t. input images\n",
        "# saliency_op = ############## YOUR CODE ##############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGQF727ALo0s",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Solution.\n",
        "# Get the maximum output prediction\n",
        "maximum_prediction = tf.reduce_max(test_predictions, 1)\n",
        "\n",
        "# Get the gradient w.r.t. input images\n",
        "saliency_op = tf.gradients(maximum_prediction, batch_test_images)[:][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4JMpe5mj6qK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Exercise.\n",
        "# Get the predicted class index for visualisation purposes.\n",
        "# pred_class_op = ############## YOUR CODE ##############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmn15p7HP7Sy",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Solution.\n",
        "# Get the predicted class index for visualisation purposes.\n",
        "pred_class_op = tf.argmax(test_predictions, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt_G1gTN3w-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the session and initialize variables\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhJx4LPJbEjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Restore pre-trained weights\n",
        "saver.restore(sess, \"baseline.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVrXDQFcK-KO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if import was done correctly by running eval on cifar test set\n",
        "# expected_accuracy = 0.94\n",
        "num_batches = 1000  # 1000 batches * 5 samples per batch = 5000\n",
        "avg_accuracy = 0.0\n",
        "for _ in range(num_batches):\n",
        "  accuracy = sess.run(test_acc)\n",
        "  avg_accuracy += accuracy\n",
        "avg_accuracy /= num_batches\n",
        "\n",
        "print (\"Accuracy {:.3f}\".format(avg_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEfs4eYE88zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get saliency maps\n",
        "smap, inp_img, predicted_class, ground_truth = sess.run(\n",
        "    [saliency_op, batch_test_images, \n",
        "     pred_class_op, tf.squeeze(batch_test_labels)])\n",
        "\n",
        "# Display \n",
        "gallery(smap, inp_img, predicted_class, ground_truth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ0eMrq7hFIV",
        "colab_type": "text"
      },
      "source": [
        "### Not that impressive, right?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG98vwnxdL6c",
        "colab_type": "text"
      },
      "source": [
        "### Let's generate the image that maximises the probability of a given class $c$\n",
        "\n",
        "The previous exercise computed\n",
        "$$\n",
        "\\frac{\\partial y_{c}}{\\partial x}\n",
        "$$\n",
        "\n",
        "Now we modify $x$ to search for $\\hat x$ that maximises $\\frac{\\partial y_{c}}{\\partial x}$ using an iterative gradient-descent like approach:\n",
        "\n",
        "$$\n",
        "x_{t+1} = \\min(1, \\max(-1, x_t + \\alpha \\frac{\\partial y_{c}}{\\partial x})), t \\in \\{0, N\\}\n",
        "$$\n",
        "$$\n",
        "x_0 = \\text{initial test image from class } c \n",
        "$$\n",
        "\n",
        "Use e.g. $\\alpha = 0.1$ and $N=10000$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnTwj2NtkUFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Exercise.\n",
        "alpha = 0.1\n",
        "N = 10000\n",
        "\n",
        "# get saliency maps\n",
        "smap, inp_img, predicted_class, ground_truth = sess.run(\n",
        "      [saliency_op, batch_test_images, \n",
        "       pred_class_op, tf.squeeze(batch_test_labels)])\n",
        "\n",
        "for t in range(N):\n",
        "  #############\n",
        "  #           #\n",
        "  # YOUR CODE #\n",
        "  #           #\n",
        "  #############\n",
        "  \n",
        "  # display transformed input image at every 1000 iterations\n",
        "  if t % 1000 == 0:\n",
        "    print ('Transformed input at iter {0:5d} out of {1:5d}'.format(int(t), int(N)))\n",
        "    gallery(smap, inp_img, predicted_class, ground_truth)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKr6H4O-ZIku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Solution.\n",
        "alpha = 0.1\n",
        "N = 10000\n",
        "\n",
        "# get saliency maps\n",
        "smap, inp_img, predicted_class, ground_truth = sess.run(\n",
        "      [saliency_op, batch_test_images, \n",
        "       pred_class_op, tf.squeeze(batch_test_labels)])\n",
        "\n",
        "for t in range(N):\n",
        "  inp_img = inp_img + alpha * smap\n",
        "  inp_img = np.minimum(1, np.maximum(-1, inp_img))\n",
        "  \n",
        "  smap = sess.run(saliency_op, \n",
        "                  feed_dict={batch_test_images: inp_img})\n",
        "  # display transformed input image at every 1000 iterations\n",
        "  if t % 1000 == 0:\n",
        "    print ('Transformed input at iter {0:5d} out of {1:5d}'.format(int(t), int(N)))\n",
        "    gallery(smap, inp_img, predicted_class, ground_truth)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}